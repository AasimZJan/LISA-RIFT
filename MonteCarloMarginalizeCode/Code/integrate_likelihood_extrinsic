#!/usr/bin/env python

"""
Integrate the extrinsic parameters of the prefactored likelihood function.
"""

#from pylal import Fr
import sys
import functools
from optparse import OptionParser, OptionGroup

import numpy

import lal
from glue.ligolw import utils, lsctables, table

import lalsimutils
import factored_likelihood
import mcsampler
import ourio

__author__ = "Evan Ochsner <evano@gravity.phys.uwm.edu>, Chris Pankow <pankow@gravity.phys.uwm.edu>, R. O'Shaughnessy"

rosDebugShowPriors = True  
rosDebugShowExcruciatingLikelihoodDetail = False

#
# Pinnable parameters -- for command line processing
#
LIKELIHOOD_PINNABLE_PARAMS = ["right ascension", "declination"]

#
# Option parsing
#

optp = OptionParser()
optp.add_option("-c", "--cache-file", default=None, help="LIGO cache file containing all data needed.")
optp.add_option("-C", "--channel-name", action="append", help="instrument=channel-name, e.g. H1=FAKE-STRAIN. Can be given multiple times for different instruments.")
optp.add_option("-p", "--psd-file", action="append", help="instrument=psd-file, e.g. H1=H1_PSD.xml.gz. Can be given multiple times for different instruments.")
optp.add_option("-x", "--coinc-xml", help="gstlal_inspiral XML file containing coincidence information.")
optp.add_option("-f", "--reference-freq", type=float, default=100.0, help="Waveform reference frequency. Required, default is 100 Hz.")
optp.add_option("-s", "--seglen", type=int, default=110, help="Minimum segment duration surrounding coing to be analyzed. (Will be rounded up to next power of 2)")
optp.add_option("-P", "--padding", type=int, default=10, help="Time window after the trigger to be included in the data segment")
optp.add_option("-m", "--time-marginalization", action="store_true", help="Perform marginalization over time via direct numerical integration. Default is false.")

#
# Add the pinnable parameters
#
pinnable = OptionGroup(optp, "Pinnable Parameters", "Specifying these command line options will pin the value of that parameter to the specified value with a probability of unity.")
for pin_param in LIKELIHOOD_PINNABLE_PARAMS:
    option = "--" + pin_param.replace(" ", "-")
    pinnable.add_option(option, type=float, help="Pin the value of %s." % pin_param)
optp.add_option_group(pinnable)

opts, args = optp.parse_args()

# FIXME: Turn into cmd line options
# minimum frequency of template
template_min_freq = 30  # too long can be a memory and time hog, particularly at 16 kHz
# minimum frequency of inner product integration
ip_min_freq = 30


#
# Gather information from the detection pipeline
#
xmldoc = utils.load_filename(opts.coinc_xml)
coinc_table = table.get_table(xmldoc, lsctables.CoincInspiralTable.tableName)
assert len(coinc_table) == 1
coinc_row = coinc_table[0]
event_time = coinc_row.get_end()
print "Coinc XML loaded, event time: %s" % str(coinc_row.get_end())

#
# Load in data and PSDs
#
data_dict, psd_dict = {}, {}

start_pad, end_pad = opts.seglen-opts.padding, opts.padding 
for inst, chan in map(lambda c: c.split("="), opts.channel_name):
    print "Reading channel %s from cache %s" % (inst+":"+chan, opts.cache_file)
    data_dict[inst] = lalsimutils.frame_data_to_non_herm_hoff(opts.cache_file, inst+":"+chan, start=int(event_time)-start_pad, stop=int(event_time)+end_pad)
    print "Frequency binning: %f, length %d" % (data_dict[inst].deltaF, len(data_dict[inst].data.data))

for inst, psdf in map(lambda c: c.split("="), opts.psd_file):
    print "Reading PSD for instrument %s from %s" % (inst, psdf)
    psd_dict[inst] = lalsimutils.pylal_psd_to_swig_psd(lalsimutils.get_psd_series_from_xmldoc(psdf, inst))
    psd_dict[inst] = lalsimutils.regularize_swig_psd_series_near_nyquist(psd_dict[inst], 80) # zero out 80 hz window near nyquist
    psd_dict[inst] =  lalsimutils.enforce_swig_psd_fmin(psd_dict[inst], ip_min_freq)           # enforce fmin at the psd level, HARD CUTOFF
    tmp = psd_dict[inst].data.data
    print "Sanity check reporting  : min is ", numpy.min(tmp[numpy.nonzero(tmp)]), " and maximum is ", numpy.max(psd_dict[inst].data.data)
    deltaF = data_dict[inst].deltaF
    # remember the PSD is one-sided, but h(f) is two-sided. The lengths are not equal.
    psd_dict[inst] = lalsimutils.extend_swig_psd_series_to_sampling_requirements(psd_dict[inst], deltaF, deltaF*(len(data_dict[inst].data.data)/2))
    print "Post-extension the new PSD has 1/df = ", 1./psd_dict[inst].deltaF, " (data 1/df = ", 1./deltaF, ") and length ", len(psd_dict[inst].data.data)
    tmp = psd_dict[inst].data.data
    print "Post-extension sanity check reporting  : min is ", numpy.min(tmp[numpy.nonzero(tmp)]), " and maximum is ", numpy.max(psd_dict[inst].data.data)
#
# Sanity checks
#
# can't FIXME: Yep, we're all totally nuts.
if sorted(psd_dict.keys()) != sorted(data_dict.keys()):
    print >>sys.stderr, "Got a different set of instruments based on data and PSDs provided."

#
# Testing
#
sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
assert len(sngl_inspiral_table) == len(coinc_row.ifos.split(","))
m1, m2 = None, None
for sngl_row in sngl_inspiral_table:
    # NOTE: gstlal is exact match, but other pipelines may not be
    assert m1 is None or (sngl_row.mass1 == m1 and sngl_row.mass2 == m2)
    m1, m2 = sngl_row.mass1, sngl_row.mass2

# FIXME: Keep this and organize
# TARGET INJECTED SIGNAL (for reference and calibration of results)
# TODO: Have an "injection" xml for reference?
#Psig = xml_to_ChooseWaveformParams_array("mdc.xml.gz")[0]  # Load in the physical parameters of the injection (=first element)

# Template descriptors
ampO =0 # sets which modes to include in the physical signal
Lmax = 2 # sets which modes to include

# FIXME: Come back to this
fiducial_epoch = lal.LIGOTimeGPS()
fiducial_epoch.gpsSeconds = event_time.seconds
fiducial_epoch.gpsNanoSeconds = event_time.nanoseconds
fref_time_off = 0   #  time relative to fiducial epoch, used to identify window to look in.  Checked empirically.
# epoch + event = time of event at f_ref
# FIXME: Geocentric? Detector specific?
print "Offset from event end time to f_ref %f" % fref_time_off

detectors = data_dict.keys()
df = data_dict[detectors[0]].deltaF     # should not be hardcoded!
# FIXME: More descriptive here
fSample = len(data_dict[detectors[0]].data.data)*data_dict[detectors[0]].deltaF  # Note two-sided

# Struct to hold template parameters
# FIXME: Lots of hardcoding going on here
P = lalsimutils.ChooseWaveformParams(
    fmin = template_min_freq, 
    radec = False, 
    incl = 0.0,
    phiref = 0.0, 
    theta = 0.0, 
    phi = 0.0,
    psi = 0.0,
    # internally we use SI units
    m1 = m1 * lal.LAL_MSUN_SI,
    m2 = m2 * lal.LAL_MSUN_SI,
    ampO = ampO,
    fref = opts.reference_freq,
    tref = fiducial_epoch,
    deltaT = 1./fSample,
    dist = factored_likelihood.distMpcRef * 1.e6 * lal.LAL_PC_SI,
    deltaF = df)


#
# Perform the Precompute stage
#
rholms_intp, cross_terms, rholms, epoch_post = factored_likelihood.PrecomputeLikelihoodTerms(fiducial_epoch, P, data_dict, psd_dict, Lmax, analyticPSD_Q=False)

#
# Set up parameters and bounds
#
# FIXME: Make t_ref_wind a cmd line parameter?
t_ref_wind = 2e-3

# FIXME: Never really used
dmin = 1. * 1.e6 * lal.LAL_PC_SI   # min distance
#dmax = 110. * 1.e6 * lal.LAL_PC_SI # max distance
Dmax = 2000. * 1.e6 * lal.LAL_PC_SI # max distance FOR ANY SOURCE EVER. EUCLIDEAN
dmaxMpc = factored_likelihood.estimateUpperDistanceBoundInMpc(rholms, cross_terms)
dmax = dmaxMpc* 1.e6 * lal.LAL_PC_SI
print "Estimated outer fiducial radius for event (Mpc): %f" %dmaxMpc

param_limits = { "psi": (0, 2*numpy.pi),
    "phi_orb": (0, 2*numpy.pi),
    "distance": (dmin, dmax),
    "right_ascension": (0, 2*numpy.pi),
    "declination": (-numpy.pi/2, numpy.pi/2),
    "t_ref": (-t_ref_wind, t_ref_wind),
    "inclination": (0, numpy.pi)
}

#
# Parameter integral sampling strategy
#
params = {}
#for param, limits in param_limits.iteritems():
#    params[param] = functools.partial(mcsampler.uniform_samp_vector(), limits[0], limits[1] )  # *limits didn't work, not sure why
sampler = mcsampler.MCSampler()

# FIXME: Address this problem?
# PROBLEM: Underlying prior samplers are not uniform.  We need two stages

#
# Psi -- polarization angle
# sampler: uniform in [0, pi)
#
psi_sampler = functools.partial(mcsampler.uniform_samp_vector, 
    param_limits["psi"][0], param_limits["psi"][1])
sampler.add_parameter("psi", 
    pdf = psi_sampler, 
    cdf_inv = None, 
    left_limit = param_limits["psi"][0], 
    right_limit = param_limits["psi"][1],
    prior_pdf = mcsampler.uniform_samp_psi)

#
# Phi - orbital phase
# sampler: uniform in [0, 2*pi)
#
phi_sampler = functools.partial(mcsampler.uniform_samp_vector, 
    param_limits["phi_orb"][0], param_limits["phi_orb"][1])
sampler.add_parameter("phi_orb",
    pdf = phi_sampler,
    cdf_inv = None, 
    left_limit = param_limits["phi_orb"][0], 
    right_limit = param_limits["phi_orb"][1],
    prior_pdf = mcsampler.uniform_samp_phase)

#
# inclination - angle of system angular momentum with line of sight
# sampler: uniform in cos [-pi, pi)
#
incl_sampler = mcsampler.cos_samp_vector # this is NOT dec_samp_vector, because the angular zero point is different!
sampler.add_parameter("inclination", 
    pdf = incl_sampler, 
    cdf_inv = None, 
    left_limit = param_limits["inclination"][0], 
    right_limit = param_limits["inclination"][1],
    prior_pdf = mcsampler.uniform_samp_theta)

#
# Distance - luminosity distance to source in parsecs
# sampler: uniform volume over [1 Mpc, Dmax)
#
dist_sampler = functools.partial(mcsampler.quadratic_samp_vector, dmax)
sampler.add_parameter("distance", 
    pdf = dist_sampler, 
    cdf_inv = None,
    left_limit = param_limits["distance"][0], 
    right_limit = param_limits["distance"][1],
    prior_pdf = numpy.vectorize(lambda x: x**2/(3*Dmax**3))
)

#
# Right ascension - angle in radians from prime meridian plus hour angle
# sampler: uniform in (0, 2pi)
#
ra_sampler = functools.partial(mcsampler.uniform_samp_vector,
    param_limits["right_ascension"][0], param_limits["right_ascension"][1])
sampler.add_parameter("right_ascension", 
    pdf = ra_sampler, 
    cdf_inv = None, 
    left_limit = param_limits["right_ascension"][0],
    right_limit =  param_limits["right_ascension"][1],
    prior_pdf = mcsampler.uniform_samp_phase)

#
# declination - angle in radians from the north pole piercing the celestial sky
# sampler: uniform in cos [-pi, pi)
#
dec_sampler = mcsampler.dec_samp_vector
sampler.add_parameter("declination", 
    pdf = dec_sampler, 
    cdf_inv = None, 
    left_limit = param_limits["declination"][0], 
    right_limit = param_limits["declination"][1],
    prior_pdf = mcsampler.uniform_samp_dec)

#
# tref - GPS time of geocentric end time
# FIXME: end time or 100 Hz?
# sampler: uniform in +/-2 ms window around estimated end time 
#
tref_sampler = functools.partial(mcsampler.uniform_samp_vector,
    param_limits["t_ref"][0], param_limits["t_ref"][1])
sampler.add_parameter("t_ref", 
    pdf = tref_sampler, 
    cdf_inv = None, 
    left_limit = param_limits["t_ref"][0], 
    right_limit = param_limits["t_ref"][1],
    # FIXME:What goes here?
    prior_pdf = functools.partial(mcsampler.uniform_samp_vector, factored_likelihood.tWindowExplore[0],factored_likelihood.tWindowExplore[1]))

if rosDebugShowPriors:
    try:
        ourio.plotParameterDistributions("input distributions", sampler)
    except:
        print " No prior plots for you!"

#
# Call the likelihood function for various extrinsic parameter values
#
# FIXME: Clean this up
nEvals = 0
nMaxEvals = 1e3
if not opts.time_marginalization:

    def likelihood_function(phi, theta, tref, phiref, incl, psi, dist):
        global nEvals
        lnL = numpy.zeros(phi.shape,dtype=numpy.float128)   # use EXTREMELY many bits
        i = 0
        if rosDebugShowExcruciatingLikelihoodDetail:
            print " Likelihood results :  "
    #    print " iteration Neff  lnL   sqrt(2max(lnL))  rho  sqrt(2 lnLmarg)   <lnL> "
        for ph, th, tr, phr, ic, ps, di in zip(phi, theta, tref, phiref, incl, psi, dist):
            P.phi = ph # right ascension
            P.theta = th # declination
            P.tref = fiducial_epoch + tr # ref. time (rel to epoch for data taking)
            P.phiref = phr # ref. orbital phase
            P.incl = ic # inclination
            P.psi = ps # polarization angle
            P.dist = di # luminosity distance
    
            lnL[i] = factored_likelihood.FactoredLogLikelihood(fiducial_epoch,P, rholms_intp, cross_terms, Lmax)
            if  rosDebugShowExcruciatingLikelihoodDetail:
                print "  + likelihood evaluation : ", i + nEvals, " :  ", lnL[i], " : overflow check ", np.exp(lnL[i])
            i+=1
    
        nEvals+=i 
        return numpy.exp(lnL)

    res, var, ret, lnLmarg, neff = sampler.integrate(likelihood_function, 
        "right_ascension", "declination", "t_ref", "phi_orb", "inclination", "psi", "distance", 
        n=10, nmax=nMaxEvals, neff=100,
        # FIXME: What here?  ROS: an estimate of the peak lnL, and a threshold on what should be returned
    #    igrandmax=rho2Net/2, igrand_threshold_fraction=0.95,
        full_output=True,verbose=True,extremely_verbose=False)

else:

    def likelihood_function(phi, theta, phiref, incl, psi, dist):
        global nEvals
        lnL = numpy.zeros(phi.shape,dtype=numpy.float128)   # use EXTREMELY many bits
        i = 0
        if rosDebugShowExcruciatingLikelihoodDetail:
            print " Likelihood results :  "
    #    print " iteration Neff  lnL   sqrt(2max(lnL))  rho  sqrt(2 lnLmarg)   <lnL> "
        for ph, th, phr, ic, ps, di in zip(phi, theta, phiref, incl, psi, dist):
            lnL[i] = factored_likelihood.NetworkLogLikelihoodTimeMarginalizedDiscrete(fiducial_epoch, rholms, cross_terms, fiducial_epoch, (-t_ref_wind, t_ref_wind), ph, th, ic, phr, ps, di, Lmax, rholms.keys())
            if  rosDebugShowExcruciatingLikelihoodDetail:
                print "  + likelihood evaluation : ", i + nEvals, " :  ", lnL[i], " : overflow check ", np.exp(lnL[i])
            i+=1
    
        nEvals+=i 
        return numpy.exp(lnL)

    res, var, ret, lnLmarg, neff = sampler.integrate(likelihood_function, 
        "right_ascension", "declination", "phi_orb", "inclination", "psi", "distance", 
        n=10, nmax=nMaxEvals, neff=100,
        # FIXME: What here?  ROS: an estimate of the peak lnL, and a threshold on what should be returned
    #    igrandmax=rho2Net/2, igrand_threshold_fraction=0.95,
        full_output=True,verbose=True,extremely_verbose=False
        )


tGPSEnd = lal.GPSTimeNow()
print " lnLmarg is ", numpy.log(res), " with expected relative error ", numpy.sqrt(var)/res
print " note neff is ", neff, "; compare neff^(-1/2) = ", 1/numpy.sqrt(neff)
exit()

try:
    ourio.plotParameterDistributionsFromSamples("results", sampler, ret,  ['ra','dec', 'tref', 'phi', 'incl', 'psi', 'dist', 'lnL'])
except:
    print " No interactive plots for you! "

# FIXME: Synch with other I/O routines
# Save the sampled points to a file
# Only store some
try:
    ourio.dumpSamplesToFile("test_like_and_samp-dump.dat", ret, ['ra','dec', 'tref', 'phi', 'incl', 'psi', 'dist', 'lnL'])
except:
    print " No saved points for you !"
