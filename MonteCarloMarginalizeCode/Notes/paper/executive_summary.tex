\newcommand\itrprm{\vec{\lambda}}
\newcommand\etrprm{\vec{\theta}}

\subsection{Motivation}

% low latency searches -- both GW and EM
The scheduled resumption of data taking in late 2015\cite{observingdocument}, with the second generation gravitational-wave interferometers in Hanford, Washington, and Livingston, Louisiana, are expected to reach sensitivities which are incrementally better than those achieved in earlier data taking runs\cite{s5s6}. The Virgo detector is also expected to resume data taking within a year of this milestone. In preparation for the next run, the LIGO and Virgo Collaborations have implemented and extensively tested a set of low latency gravitational-wave detection pipelines\cite{gstlal,mbta,cwb}, capable of compact binary event detection in latencies of a few minutes or less from the coalescence time. These pipelines trade speed and breadth of analysis for the ability to accurately determine all but a few of the parameters of the coalescence. Having a more accurate estimation of the parameters is valuable not only to gravitational-wave science, but also is useful to provide electromagnetic observatories information to aid in pointing. Many astrophysical phenomena which could create transient gravitational waves will also have electromagnetic signatures that may rapidly decay, and gravitational-wave interferometer networks often cannot localize GW events to better than a few hundred square degrees on the sky\cite{skylocpapers}, thus prompting follow-up observations occur expeditiously after the initial identification as well as localized promptly and accurately. While several Bayesian algorithms for GW parameter estimation have been employed in the past, the time scale of a full parameter estimation analysis remains at a much higher latency than the initial detection.

% MC integration scheme
Given the inherent serial nature of current Bayesian parameter estimation schemes, in order to make a breakthrough in the computational time, it is necessary to either reduce the cost per likelihood computation or devise a scheme which is inherently parallel from the start. Our scheme accomplishes both, as we propose to pre-calculate a data set of source intrinsic components of the likelihood function dependent only on mass and explore the parameter sauce with a Monte-Carlo (but not Markovian) integration scheme to perform quick and independent likelihood evaluations. This scheme mitigates the cost of waveform generation since only one waveform is ever really generated thus allowing the use of waveform families which may have significant computational overhead per waveform. In addition, as the low frequency sensitivity of the second generation interferometers evolves, generation of waveforms becomes more costly, since the computational cost of time-domain waveforms scales as a power law. Most current schemes also require the costly evaluation of an inner product per likelihood sample, which we circumvent. Thus, we gain the additional benefit of better parameter estimation through lower frequency waveforms with only marginally increased cost. Combination these benefits should provide a more accurate calculation by capturing more of the features of the waveform in the likelihood evaluation with a drastically reduced and parallelizable computational cost.

Since a direct Monte Carlo integration is independent of the previous samples drawn, all likelihood evaluations can be performed in parallel. While our scheme is not strictly independent of the previous samples drawn, the computation is still parallel, the final result independent, the speed of convergence enhanced, and evaluations from parallel instances are trivially combined. Contrast this with a na\"ive MCMC scheme which requires waveform generation based on the likelihood space which has been evaluated previously (thus being serial), with a comparatively low number of effective sample points per likelihood evaluation. An additional benefit in our scheme is that the evidence is available immediately, and the variance of the integral can be used to control the desired level of convergence. This calculation is vastly less complex than comparable algorithms to derive the evidence from MCMC\cite{thermoint}.

We also propose to make use of information that is retrieved from both the low-latency gravitational-wave search as well as any other low-latency process to augment our own results. From the gravitational-wave search, we obtain knowledge of the event time --- needed only in a general sense to restrict the amount of data processing involved to tractable levels --- and information regarding the masses, used later to center the search space in the searched intrinsic parameters. Fast algorithms which can produce an accurate estimate of the sky position using only the information provided from the GW search\cite{bayestar} can also be utilized to speed up computation.

% TODO: Can we edit this down further?
Moreover, it is known\cite{glitch,detchar,glitch_pe} that the quality or stationarity of the data could influence the detection of an astrophysical event, or in the worst cases, trigger detection pipelines from the accidental coincidence of environmental or mechanical phenomenon which are not successfully cleaned from the data stream. The ability of a Bayesian parameter estimation algorithm to deal with such influences is an active area of study\cite{glitchfitting}. Even so, a detailed parameter estimation study can also influence the statistical significance of a putative event by downranking or upranking based on the model support from the parameter estimation itself.

% waveform generation cost
Several waveform families representing the gravitational radiation from coalescing binaries exist and are in common use in the aforementioned searches\cite{waveforms}. In general, the more physical features that the family is able to describe, the higher the computational cost involved in generating a waveform from that family. As was mentioned in Section \ref{sec:introduction}, current parameter estimation schemes usually require a substantial amount of waveforms to be generated --- na\"ively one per likelihood evaluation --- in order to evaluate the entire space. For the full space later described in this section, the waveform cost begins to dominate the overall cost of the calculation. In the scheme presented here, one novel aspect is that the waveform is effectively only generated once, with computational gains coming from manipulation of that waveform rather than full regeneration of the waveform itself, as well as utilizing the current estimates of some of the parameters derived from the gravitational-wave searches and any quick follow ups that have been done. This effectively reduces the volume required to be searched in the multi-dimensional parameter space by several orders.


\subsection{Preliminaries}
We begin with the division of the parameter space of compact binary coalescence waveforms. We first define the difference between ``intrinsic'' and ``extrinsic'' parameters. We define $\itrprm$ as the set of intrinsic parameter as those corresponding to the physical configuration of a binary with component masses $m_1$ and $m_2$: $\itrprm=\{\mc,\eta,\Lambda_1,\Lambda_2,\vec{S}_1,\vec{S}_2,\vec{L}\}$, where $\mc$ and $\eta$ are the chirp mass ($(m_1m_2)^{3/5}/(m_1+m_2)^{1/5}$) and symmetric mass ratio ($m_1m_2/(m_1+m_2)^2$), $\Lambda_1$ and $\Lambda_2$ are the tidal numbers of each component mass\footnote{Black holes have no tidal number and thus $\Lambda=0$}, and finally $\vec{S}_1$ and $\vec{S}_2$ correspond to the spin vectors of the component compact objects\footnote{$\vec{L}$, the overall angular momentum of the system is important in the case where the spins are not aligned with the orbital angular momentum, thus causing precession of the orbital plane}. We emphasize in this work rapid determination of source masses --- and possibly compact object type --- thus focusing attention exclusively on $\itrprm=\{\mc,\eta\}$. While the impact of spin and tidal parameters on the waveform are important, they are also potentially complicate the computation of the likelihood in the scheme described later. We thus leave the remaining intrinsic parameters to be built upon in future work.

The extrinsic parameters can be interpreted as the effect of the waveform's arrival and response on a given gravitational-wave detector. For a set of gravitational-wave interferometers, a seven-dimensional space of extrinsic parameters is defined as $\etrprm=\{t_c,\alpha,\delta,\iota,D,\psi,\phi\}$, where $t_c$ is a reference time (usually relative to the geocentric time of coalescence), $\alpha$ and $\delta$ are the right ascension and declination, $\iota$ is the inclination angle of the binary's angular momentum vector and the line of sight to Earth, $D$ is the luminosity distance to the binary\footnote{For the sources considered in this paper, the redshift correction is assumed to be negligible}, $\psi$ is the azimuthal angle of the wave's plane of disturbance to the plane of the arms of the detector, and $\phi$ is the orbital phase of the binary at coalescence. Several subsets of these parameters have well-known (particularly in the non-spinning case) correlations.
